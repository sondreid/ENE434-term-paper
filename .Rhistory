US retail employment")
classical_decomp %>%
select(Employed, trend, seasonal) %>%
ts() %>%
autoplot() +
labs(title = "Classical additive decomposition of total
US retail employment")
df <- us_employment
df
View(df)
library(lubridate)
year(df$Month[1])
df <- us_employment %>% mutate(Year = year(Month))
df
View(df)
library(fpp3)
attach(us_employment)
library(ggfortify)
library(lubridate)
df <- us_employment %>% mutate(Year = year(Month))
classical_decomp <- df %>%
filter(Year >= 1990) %>%
model(classical_decomposition(Employed, type = "additive")) %>%
components()
classical_decomp %>%
select(Employed, trend, seasonal) %>%
ts() %>%
autoplot() +
labs(title = "Classical additive decomposition of total
US retail employment")
classical_decomp %>% select(Employed)
library(fpp3)
attach(us_employment)
library(ggfortify)
library(lubridate)
df <- us_employment %>% mutate(Year = year(Month))
classical_decomp <- df %>%
filter(Year >= 1990) %>%
select(Employed, trend, seasonal) %>%
model(classical_decomposition(Employed, type = "additive")) %>%
components()
classical_decomp %>%
ts() %>%
autoplot() +
labs(title = "Classical additive decomposition of total
US retail employment")
View(classical_decomp)
classical_decomp %>% select(Employed)
classical_decomp %<>% select(-Series_ID)
library(magrittr)
classical_decomp %<>% select(-Series_ID)
classical_decomp %<>% select(-.model, -Month, .Series_ID)
classical_decomp %<>% select(-.model, -Month)
classical_decomp
classical_decomp
df <- us_employment %>% mutate(Year = year(Month))
classical_decomp <- df %>%
filter(Year >= 1990) %>%
model(classical_decomposition(Employed, type = "additive")) %>%
components()
classical_decomp
plot(classical_decomp)
install.packages("X11")
library(X11)
install.packages("X11")
install.packages("Rtools")
source("data.r")
source("data.r")
2+2
# Generating y_t
generate_y <- function(fit, n) {
#' Function that passes the standard deviation of the residuals of our optim-
#' al ARIMA model
#' Automatically finds and passes ar and ma terms to the arima.sim (stats pa-
#' ckage), and returns the generated series
sigma <- sd(residuals(fit)$.resid)
ar_terms <- (fit %>%
coefficients %>%
filter(str_detect(term,"ar")))$estimate %>%
c(.) # AR terms and their coefficients
sma_terms <- (fit %>% coefficients
%>% filter(str_detect(term, "sma")))$estimate %>%
c(.)
arima_sim_model <- list(order = c(5, 1, 0),
ar = ar_terms,
sma = sma_terms)
y <- arima.sim(n = n,
arima_sim_model,
sd = sigma)
return(y)
}
# Simulation function
simulate <- function(fit, R, train_length , h ) {
#' Function that generates a new series x based on an arima simulation retu-
#' rned by generate_y.
#' Compares two models, and populates which contains a series of forecast e-
30
#' valuation metrics.
#' Returns the populated matrix.
res <- matrix(0,2,5)
colnames(res) <- c("RMSE", "MASE", "MAE", "MAPE", "RMSSE")
rownames(res) <- c("VAR multivariate", "ARIMA yt")
for(i in 1:R){
y <- diff(generate_y(fit, train_length+h))
y_e <- y[1:train_length]
y_t <- y[(train_length+1):(train_length+h)]
x <- c()
x[1] <- y[1]
for (j in 2:(train_length+h)) {
x[j] <- 0.5*y[j-1] + 0.5*x[j-1] + rnorm(n = 1,
mean = 0,
sd = sd(y))
}
x_e <- x[1:train_length]
x_t <- x[(train_length+1):(train_length+h)]
data_x_y = data.frame(date = (1:train_length),
x_e = x_e,
y_e = y_e) %>%
as_tsibble(index = date)
var_multi <- vars:: VAR(data_x_y[,2:3],
p = 1,
type = "const") # VAR(1) model
arima_uni <- data_x_y %>%
model(Arima = ARIMA(y_e ~ 0 + pdq(1,0,0) + PDQ(0,0,0))) # ARIMA pdq(1,0,0) model
var_resids <- y_t - predict(var_multi, n.ahead = h)$fcst$y_e[,1]
arima_resids <- y_t - (arima_uni %>% forecast(h = h))$.mean
res[1,1] <- res[1,1] + RMSE(var_resids)/R
res[2,1] <- res[2,1] + RMSE(arima_resids)/R
res[1,2] <- res[1,2] + MASE(.resid = var_resids,
.train = y_e,
.period = 12)/R
res[2,2] <- res[2,2] + MASE(.resid = arima_resids,
.train = y_e,
.period = 12)/R
res[1,3] <- res[1,3] + MAE(.resid = var_resids)/R
31
res[2,3] <- res[2,3] + MAE(.resid = arima_resids)/R
res[1,4] <- res[1,4] + fabletools::MAPE(.resid = var_resids,
.actual = y_t,
.period = 12)/R
res[2,4] <- res[2,4] + fabletools::MAPE(.resid = arima_resids,
.actual = y_t,
.period = 12)/R
res[1,5] <- res[1,5] + RMSSE(.resid = var_resids,
.train = y_e,
.period = 12)/R
res[2,5] <- res[2,5] + RMSSE(.resid = arima_resids,
.train = y_e,
.period = 12)/R
}
return(res)
}
# Wrapper function
wrapperSim <- function(R, sample_size, test_ratio) {
#' Wrapper function that splits the unemployment series into
#' test and training lengths based on an input sample length and
#' test ratio of the overall series length.
#' Passes this as parameters to the simulate function
cl <- parallel::makeCluster(parallel::detectCores()) ### Make clusters
doParallel::registerDoParallel(cl)
train_length <- floor(sample_size * (1 - test_ratio))
h <- ceiling(sample_size * test_ratio)
print(paste("Training length: ", train_length))
print(paste("h : ", h))
start <- (nrow(unemployment_train_ts) - sample_size)
sim_res <- simulate(fit_arima_optimal, R, train_length, h) %>%
as.data.frame() %>%
mutate("Sample length" = sample_size)
parallel::stopCluster(cl)
return(sim_res) }
summary(fi_garch)
##### Load libraries ######
library(tidyverse)
library(fpp3)
library(kableExtra)
library(fGarch)
library(lubridate)
library(readxl)
library(magrittr)
library(forecast)
library(dynlm)
library(fable)
library(tseries)
## Seasonal decompositon of Danish electricity consumption
cons_comp_dk = cons_ts %>% model(
STL(DK ~ trend(window=7) + season(window="periodic"))
) %>% components
forecast::ggtsdisplay(cons$DK, plot_type='partial',
lag.max = 24,
theme = theme_bw(),
main = "Elecitricity consumption in Denmark ACF and PACF plots ")
# Perform differencing
cons_diff_dk <- cons %>% mutate(DK = difference(DK,7)) %>% dplyr::filter(!is.na(DK)) #Take first order difference
fit_arima_optimal_cons_dk <-
cons %>%
as_tsibble(index = date) %>%
model(arima_optimal =  ARIMA(DK, stepwise = FALSE, approximation = FALSE))
### Data retrieval ##
ets = read_csv("http://jmaurit.github.io/analytics/labs/data/eua-price.csv") ## Carbon pricing data
colnames(ets) = c("date", "price")                                                # Change rownames
elspot = read_csv("http://jmaurit.github.io/norwayeconomy/data_series/elspot.csv") ##
ets["month"] = month(ets$date)
ets["year"] = year(ets$date)
ets_mon = ets %>% group_by(month, year) %>% summarise(
price = mean(price))
ets_mon["day"] = 1
ets_mon = ets_mon %>% arrange(year, month)
ets_mon = ets_mon %>% mutate(date = make_date(year, month, day))
## Convert to monthly data
ets %<>%
mutate(month = month(date)) %>%
group_by(month) %>%
summarise(ets_mon = mean(price),
year = year(date),
month = month,
day  = 1) %>%
ungroup() %>%
mutate(date = make_date(year, month, day ))
# Join carbon pricing data and
power_df <- elspot %>% inner_join(ets_mon[c("price", "date")], by="date")
power_DK_df <- power_df %>% dplyr:: select(DK1, DK2, date, price)
## Scale to mwh
power_DK_df %<>% mutate(DK1 = DK1/1000,
DK2 = DK2/1000)
## Daily consumption data
cons = read_csv2("http://jmaurit.github.io/analytics/labs/data/consumption-per-country_2019_daily.csv")
cons["date"] = as.Date(cons$date, format="%d/%m/%Y")
cons_ts <- tsibble(cons, index=date)
## Seasonal decompositon of Danish electricity consumption
cons_comp_dk = cons_ts %>% model(
STL(DK ~ trend(window=7) + season(window="periodic"))
) %>% components
cons_comp_no = cons_ts %>% model(
STL(NO ~ trend(window=7) + season(window="periodic"))
) %>% components
cons_comp_dk %>%  autoplot()
cons_comp_no %>%  autoplot()
forecast::ggtsdisplay(cons$DK, plot_type='partial',
lag.max = 24,
theme = theme_bw(),
main = "Elecitricity consumption in Denmark ACF and PACF plots ")
unitroot_kpss(cons$DK)
adf.test(cons$DK)
# Perform differencing
cons_diff_dk <- cons %>% mutate(DK = difference(DK,7)) %>% dplyr::filter(!is.na(DK)) #Take first order difference
unitroot_kpss(cons_diff_dk$DK)
adf.test(cons_diff_dk$DK) #Stationary
# New ACF and PACF plots
forecast::ggtsdisplay(cons_diff_dk$DK, plot_type='partial',
lag.max = 24,
theme = theme_bw(),
main = "Elecitricity consumption in Denmark (difference) ACF and PACF plots ")
fit_arima_optimal_cons_dk <-
cons %>%
as_tsibble(index = date) %>%
model(arima_optimal =  ARIMA(DK, stepwise = FALSE, approximation = FALSE))
fit_arima_manual_cons_dk <- cons %>% as_tsibble(index = date) %>%
model(arima_101111       = ARIMA(DK ~ 0 + pdq(1,0,1) + PDQ(1,1,1)))
fit_cons_dk  <-  fit_arima_manual_cons_dk  %>% bind_cols(fit_arima_optimal_cons_dk)
elspot_data <- read_csv("elspot-prices_2019_daily_nok.csv") # Load data
colnames(elspot_data) <- elspot_data[2,]
elspot_data <- elspot_data[3:nrow(elspot_data),]
colnames(elspot_data)[1] <- "date"
elspot_data  %<>%
mutate(date = lubridate::dmy(date),
FI = as.numeric(gsub(",", ".", FI)))  %>%  #Substitute commas
select(date, FI)  %>%
as_tsibble(index = date)
#Plot of finnish electricity prices and ACF/PACF plots
forecast::ggtsdisplay(elspot_data$FI, plot_type='partial',
lag.max = 24,
theme = theme_bw(),
main = "Finnish electricity prices in 2019 NOK mwh")
fi_garch <- garchFit(~arma(1,1) + garch(1,1), data = elspot_data$FI, trace = F)
summary(fi_garch)
fi_garch@residuals
hist(fi_garch@residuals)
ggtsdisplay(fi_garch@residuals)
ggtsdisplay(Residuals,
plot.type = "histogram",
lag.max = 24,
theme = theme_bw(),
main = "Residuals of ETS(A,Ad,A) model")
ggtsdisplay(fi_garch@residuals)
hist(fi_garch@residuals)
ggtsdisplay(fi_garch@residuals)
ggtsdisplay(fi_garch@residuals, plot.type = "histogram")
el_spot <- read.csv("G:\Dokumenter\Google drive folder\NHH\Master\BAN403\Exam\Repository\kolonial data og informasjon\el_spot_prices.csv")
library(tidverse)
el_spot <- read.csv("G:\Dokumenter\Google drive folder\NHH\Master\BAN403\Exam\Repository\kolonial data og informasjon\el_spot_prices.csv")
# Save pv_df
#save(pv_df, file = "pv_df.Rdata")
load("pv_df.Rdata")
setwd("G:/Dokumenter/Google drive folder/NHH/Master/ENE434/Term assignment/repo")
############ Data wrangling ############
### Libraries ######
library(EIAdata)
library(fpp3)
library(tidyverse)
library(magrittr)
library(lubridate)
### Weather data:
# Three stations as of now: Southern rough, Houston, LBJ road
texas_weather <- read.csv("Data/texas_weather.csv") %>%
dplyr::select(NAME:TMIN) %>%
rename(station_name = NAME,
date = DATE,
temp_avg = TAVG,
temp_min = TMIN,
temp_max = TMAX) %>%
mutate(date = lubridate::ymd(date))
retrieveHour <- function(x) {
#'
#'Function that extracts hour  from date
hourVec <- (strsplit(x, split = ""))[[1]][13:14]
return (paste(hourVec[1], hourVec[2], ":00", sep = ""))
}
retrieveDate <- function(x) {
#'
#'Function that extracts hour  from date
date_vec <- (strsplit(x, split = ""))[[1]][2:11]
string <- ""
for (symbol in date_vec) {
if (symbol == ".") next
string <- paste(string, symbol, sep = "")
}
return (string)
}
processFrameGeneration <- function(df, type) {
#' Readies a generation data frame
#' @df : dataframe, input generation data frame
#' @type: string, type of power generation (e.g natural gas or nuclear)
#' @return: returns a processed data frame
oldName <- colnames(df)[1]
df %<>%
mutate(dateRaw = rownames(df),
hour = retrieveHour(dateRaw),
date = mapply(retrieveDate, dateRaw),
type = type,
date = lubridate::ymd(date)) %>%
rename("mWh_generated" = oldName) %>%
dplyr::select(-dateRaw)
rownames(df) <- seq(1, nrow(df))
return (df)
}
load(file = "Data/total_generation_data.Rdata")
load(file = "Data/texas_demand.Rdata")
key <- "81a7388709d31bb149eb1cc9c7eba736"
## All in local time
## Generation data
texas_nuclear_generation <- getEIA(ID = "EBA.TEX-ALL.NG.NUC.HL", key = key) %>% as.data.frame()
texas_gas_generation <- getEIA(ID ="EBA.TEX-ALL.NG.NG.HL" , key = key) %>% as.data.frame()
texas_wind_generation <- getEIA(ID ="EBA.TEX-ALL.NG.WND.HL" , key = key) %>% as.data.frame()
texas_solar_generation <- getEIA(ID ="EBA.TEX-ALL.NG.SUN.HL" , key = key) %>% as.data.frame()
texas_coal_generation <- getEIA(ID ="EBA.TEX-ALL.NG.COL.HL" , key = key) %>% as.data.frame()
texas_hydro_generation <- getEIA(ID ="EBA.TEX-ALL.NG.WAT.HL" , key = key) %>% as.data.frame()
texas_other_generation <- getEIA(ID ="EBA.TEX-ALL.NG.OTH.HL" , key = key) %>% as.data.frame()
texas_generation <- getEIA(ID = "EBA.TEX-ALL.NG.HL", key = key) %>% as.data.frame()
## Demand data
texas_demand <- getEIA(ID = "EBA.TEX-ALL.D.HL", key = key) %>% as.data.frame()
### Weather data:
# Three stations as of now: Southern rough, Houston, LBJ road
texas_weather <- read.csv("Data/texas_weather.csv") %>%
dplyr::select(NAME:TMIN) %>%
rename(station_name = NAME,
date = DATE,
temp_avg = TAVG,
temp_min = TMIN,
temp_max = TMAX) %>%
mutate(date = lubridate::ymd(date))
retrieveHour <- function(x) {
#'
#'Function that extracts hour  from date
hourVec <- (strsplit(x, split = ""))[[1]][13:14]
return (paste(hourVec[1], hourVec[2], ":00", sep = ""))
}
retrieveDate <- function(x) {
#'
#'Function that extracts hour  from date
date_vec <- (strsplit(x, split = ""))[[1]][2:11]
string <- ""
for (symbol in date_vec) {
if (symbol == ".") next
string <- paste(string, symbol, sep = "")
}
return (string)
}
processFrameGeneration <- function(df, type) {
#' Readies a generation data frame
#' @df : dataframe, input generation data frame
#' @type: string, type of power generation (e.g natural gas or nuclear)
#' @return: returns a processed data frame
oldName <- colnames(df)[1]
df %<>%
mutate(dateRaw = rownames(df),
hour = retrieveHour(dateRaw),
date = mapply(retrieveDate, dateRaw),
type = type,
date = lubridate::ymd(date)) %>%
rename("mWh_generated" = oldName) %>%
dplyr::select(-dateRaw)
rownames(df) <- seq(1, nrow(df))
return (df)
}
## Load preassembled Rdata files
#load(file = "Data/total_generation_data.Rdata")
#load(file = "Data/texas_demand.Rdata")
generation_data <- processFrameGeneration(texas_nuclear_generation, "nuclear") %>%
bind_rows(processFrameGeneration(texas_gas_generation, "gas"),
processFrameGeneration(texas_coal_generation, "coal"),
processFrameGeneration(texas_solar_generation, "solar"),
processFrameGeneration(texas_wind_generation, "wind"),
processFrameGeneration(texas_hydro_generation, "hydro"),
processFrameGeneration(texas_other_generation, "other"))
total_generation_data <- generation_data %>%
group_by(hour, date) %>%
summarise(type = "total",
date = date,
hour =  hour,
mWh_generated = sum(mWh_generated))
texas_demand  %<>%
mutate(dateRaw = rownames(texas_demand),
hour = retrieveHour(dateRaw),
date = mapply(retrieveDate, dateRaw),
date = lubridate::ymd(date)) %>%
rename("mWh_demand" = colnames(texas_demand)[1]) %>%
dplyr::select(-dateRaw)
View(texas_demand)
## Demand data
texas_demand <- getEIA(ID = "EBA.TEX-ALL.D.HL", key = key) %>% as.data.frame()
### Weather data:
# Three stations as of now: Southern rough, Houston, LBJ road
texas_weather <- read.csv("Data/texas_weather.csv") %>%
dplyr::select(NAME:TMIN) %>%
rename(station_name = NAME,
date = DATE,
temp_avg = TAVG,
temp_min = TMIN,
temp_max = TMAX) %>%
mutate(date = lubridate::ymd(date))
retrieveHour <- function(x) {
#'
#'Function that extracts hour  from date
hourVec <- (strsplit(x, split = ""))[[1]][13:14]
return (paste(hourVec[1], hourVec[2], ":00", sep = ""))
}
retrieveDate <- function(x) {
#'
#'Function that extracts hour  from date
date_vec <- (strsplit(x, split = ""))[[1]][2:11]
string <- ""
for (symbol in date_vec) {
if (symbol == ".") next
string <- paste(string, symbol, sep = "")
}
return (string)
}
processFrameGeneration <- function(df, type) {
#' Readies a generation data frame
#' @df : dataframe, input generation data frame
#' @type: string, type of power generation (e.g natural gas or nuclear)
#' @return: returns a processed data frame
oldName <- colnames(df)[1]
df %<>%
mutate(dateRaw = rownames(df),
hour = mapply(retrieveHour,dateRaw),
date = mapply(retrieveDate, dateRaw),
type = type,
date = lubridate::ymd(date)) %>%
rename("mWh_generated" = oldName) %>%
dplyr::select(-dateRaw)
rownames(df) <- seq(1, nrow(df))
return (df)
}
## Load preassembled Rdata files
#load(file = "Data/total_generation_data.Rdata")
#load(file = "Data/texas_demand.Rdata")
generation_data <- processFrameGeneration(texas_nuclear_generation, "nuclear") %>%
bind_rows(processFrameGeneration(texas_gas_generation, "gas"),
processFrameGeneration(texas_coal_generation, "coal"),
processFrameGeneration(texas_solar_generation, "solar"),
processFrameGeneration(texas_wind_generation, "wind"),
processFrameGeneration(texas_hydro_generation, "hydro"),
processFrameGeneration(texas_other_generation, "other"))
total_generation_data <- generation_data %>%
group_by(hour, date) %>%
summarise(type = "total",
date = date,
hour =  hour,
mWh_generated = sum(mWh_generated))
texas_demand  %<>%
mutate(dateRaw = rownames(texas_demand),
hour = mapply(retrieveHour,dateRaw),
date = mapply(retrieveDate, dateRaw),
date = lubridate::ymd(date)) %>%
rename("mWh_demand" = colnames(texas_demand)[1]) %>%
dplyr::select(-dateRaw)
rownames(texas_demand) <- seq(1, nrow(texas_demand))
View(texas_demand)
demand_hour <- texas_demand %>%
group_by(date) %>%
summarise(mWh_demand_per_day = sum(mWh_demand))
View(demand_hour)
total_generation_daily <-   group_by(date) %>%
summarise(mWh_demand_per_day = sum(mWh_generated_daily))
total_generation_daily <- total_generation_data %>%
group_by(date) %>%
summarise(mWh_demand_per_day = sum(mWh_generated_daily))
total_generation_daily <- total_generation_data %>%
group_by(date) %>%
summarise(mWh_generated_daily = sum(mWh_generated))
View(total_generation_daily)
